{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPnm91syl3rl"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/gdrive')\n",
    "%cd /content/gdrive/MyDrive/NCS\n",
    "path = os.getcwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9phB1HQKIQX"
   },
   "outputs": [],
   "source": [
    "\n",
    "import gzip\n",
    "import pandas as pd\n",
    "file_path ='Gene Data/21050/data.trn.gz'\n",
    "with gzip.open(file_path, 'rt') as f:\n",
    "   df = pd.read_csv(f, header=None, sep='\\s+');\n",
    "\n",
    "print(df.shape)\n",
    "X = df.iloc[:, :-1]\n",
    "\n",
    "y= df.iloc[:,-1]\n",
    "unique_labels = y.unique()\n",
    "print(\"Các nhãn duy nhất trong tập dữ liệu:\", unique_labels)\n",
    "num_classes = y.nunique()\n",
    "label_counts = y.value_counts()\n",
    "print(\"Số lượng mẫu cho mỗi nhãn:\")\n",
    "print(label_counts)\n",
    "if 13 in label_counts.index:\n",
    "    print(f\"Số lượng mẫu cho nhãn 13: {label_counts[13]}\")\n",
    "else:\n",
    "    print(\"Nhãn 13 không có trong tập dữ liệu.\")\n",
    "missing_labels = y.isnull().sum()\n",
    "print(f\"Số lượng mẫu không có nhãn (NaN): {missing_labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llHfo3eZjLaS"
   },
   "outputs": [],
   "source": [
    "# CHọn đặc trưng với SVM, RF, DT\n",
    "import os\n",
    "import logging\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "warnings.filterwarnings('ignore')\n",
    "datasets_and_n_SF = [(20685,545),(20711,111),(21050,72),\n",
    " (21122, 271),\n",
    "    (29354, 28), (30784, 171), (31312, 213), (31552, 79),\n",
    "    (32537, 96), (33315, 483), (37364, 59),\n",
    "    (39582, 644), (39716, 124), (44077, 227),(36895,39)]\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None, sep='\\s+')\n",
    "        logging.info(f\"Đọc dữ liệu từ file: {file_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Không tìm thấy file: {file_path}\")\n",
    "        return None\n",
    "\n",
    "def scale_data(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    logging.info(\"Dữ liệu đã được chuẩn hóa.\")\n",
    "    return X_scaled\n",
    "def select_features_with_rf(X_scaled, y, n_SF, n_estimators=100):\n",
    "    start_time = time.time()\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rf.fit(X_scaled, y)\n",
    "    importances = rf.feature_importances_\n",
    "    indices = importances.argsort()[::-1][:n_SF]\n",
    "    X_selected = X_scaled[:, indices]\n",
    "\n",
    "    elapsed_time = time.time() - start_time  # Thời gian kết thúc\n",
    "    logging.info(f\"Chọn {len(indices)} đặc trưng quan trọng nhất bằng Random Forest. Thời gian: {elapsed_time:.2f} giây.\")\n",
    "    return X_selected, indices, importances, elapsed_time\n",
    "\n",
    "def select_features_with_dt(X_scaled, y, n_SF):\n",
    "    start_time = time.time()  # Thời gian bắt đầu\n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_scaled, y)\n",
    "    importances = dt.feature_importances_\n",
    "\n",
    "    indices = importances.argsort()[::-1][:n_SF]\n",
    "    X_selected = X_scaled[:, indices]\n",
    "\n",
    "    elapsed_time = time.time() - start_time  # Thời gian kết thúc\n",
    "    logging.info(f\"Chọn {len(indices)} đặc trưng quan trọng nhất bằng Decision Tree. Thời gian: {elapsed_time:.2f} giây.\")\n",
    "    return X_selected, indices, importances, elapsed_time\n",
    "\n",
    "def select_features_with_svm(X_scaled, y, k):\n",
    "    start_time = time.time()  # Thời gian bắt đầu\n",
    "    mi = SelectKBest(mutual_info_classif, k=k)\n",
    "    X_selected = mi.fit_transform(X_scaled, y)\n",
    "    elapsed_time = time.time() - start_time  # Thời gian kết thúc\n",
    "    logging.info(f\"Chọn {k} đặc trưng quan trọng nhất bằng SVM với Mutual Information. Thời gian: {elapsed_time:.2f} giây.\")\n",
    "    return X_selected, mi, elapsed_time\n",
    "\n",
    "\n",
    "def save_selected_feature_names_to_csv(X, selected_features, output_directory, filename):\n",
    "    selected_feature_names = X.columns[selected_features]\n",
    "    selected_features_file = os.path.join(output_directory, filename)\n",
    "    pd.DataFrame(selected_feature_names, columns=['Selected Features']).to_csv(selected_features_file, index=False)\n",
    "    logging.info(f\"Tên các đặc trưng đã được chọn lưu vào file: {selected_features_file}\")\n",
    "\n",
    "\n",
    "def save_feature_extraction_times(output_directory, times_dict, filename):\n",
    "    times_file = os.path.join(output_directory, filename)\n",
    "    pd.DataFrame(times_dict).to_csv(times_file, index=False)\n",
    "    logging.info(f\"Thời gian trích đặc trưng lưu vào file: {times_file}\")\n",
    "\n",
    "for dataset, n_SF in datasets_and_n_SF:\n",
    "    logging.info(f\"Bắt đầu xử lý dataset: {dataset} với {n_SF} đặc trưng cần chọn.\")\n",
    "    file_path = f'Gene Data/{dataset}/data.trn.gz'\n",
    "    output_directory = os.path.join('Thuc Nghiem', 'Selected Features', 'Results', '08.10_ML', str(dataset))\n",
    "    log_file = os.path.join(output_directory, 'experiment_log.log')\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logging.info(f\"Bắt đầu quá trình chọn lọc đặc trưng cho dataset {dataset}.\")\n",
    "\n",
    "    df = load_data(file_path)\n",
    "    if df is not None:\n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "        X_scaled = scale_data(X)\n",
    "        times_dict = {'Method': [], 'Time (seconds)': []}\n",
    "        X_selected_rf, selected_features_rf, importances_rf, rf_time = select_features_with_rf(X_scaled, y, n_SF)\n",
    "        times_dict['Method'].append('Random Forest')\n",
    "        times_dict['Time (seconds)'].append(rf_time)\n",
    "        logging.info(f\"Số đặc trưng được chọn với Random Forest: {len(selected_features_rf)}\")\n",
    "        X_selected_dt, selected_features_dt, importances_dt, dt_time = select_features_with_dt(X_scaled, y, n_SF)\n",
    "        times_dict['Method'].append('Decision Tree')\n",
    "        times_dict['Time (seconds)'].append(dt_time)\n",
    "        logging.info(f\"Số đặc trưng được chọn với Decision Tree: {len(selected_features_dt)}\")\n",
    "        X_selected_svm, mi_selector, svm_time = select_features_with_svm(X_scaled, y, k=n_SF)\n",
    "        times_dict['Method'].append('SVM (Mutual Information)')\n",
    "        times_dict['Time (seconds)'].append(svm_time)\n",
    "        logging.info(f\"Số đặc trưng được chọn với SVM: {mi_selector.get_support().sum()}\")\n",
    "        save_selected_feature_names_to_csv(X, selected_features_rf, output_directory, filename=f'{n_SF}_rf_selected_feature_names.csv')\n",
    "        save_selected_feature_names_to_csv(X, selected_features_dt, output_directory, filename=f'{n_SF}_dt_selected_feature_names.csv')\n",
    "        save_selected_feature_names_to_csv(X, mi_selector.get_support(), output_directory, filename=f'{n_SF}_svm_selected_feature_names.csv')\n",
    "        save_feature_extraction_times(output_directory, times_dict, filename=f'{n_SF}_feature_extraction_times.csv')\n",
    "\n",
    "    logging.info(f\"Hoàn tất xử lý dataset: {dataset}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "63ukb4er-eqW"
   },
   "outputs": [],
   "source": [
    "###Huấn luyện với 4 giải thuật\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneOut\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, compression='gzip')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi tải dữ liệu từ file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_selected_features(selected_features_file):\n",
    "    try:\n",
    "        selected_features = pd.read_csv(selected_features_file)\n",
    "        return selected_features.iloc[:, 0].tolist()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi tải danh sách đặc trưng từ file {selected_features_file}: {e}\")\n",
    "        return None\n",
    "def scale_data(X):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "def save_results_to_csv(results_df, output_directory, filename):\n",
    "    file_path = os.path.join(output_directory, filename)\n",
    "    try:\n",
    "        results_df.to_csv(file_path, index=False)\n",
    "        logging.info(f\"Kết quả đã được lưu vào file {file_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Lỗi khi lưu kết quả vào file {file_path}: {e}\")\n",
    "\n",
    "\n",
    "def train_and_evaluate_models_cv(X, y, n_runs=10):\n",
    "    models = {\n",
    "        'SVM': SVC(C=100000, kernel='rbf', gamma='scale', class_weight='balanced', random_state=42),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "        'XGBoost (GPU)': XGBClassifier(\n",
    "            n_estimators=200, learning_rate=0.01, max_depth=3, min_child_weight=1, gamma=1,\n",
    "            subsample=0.8, colsample_bytree=0.8, objective='multi:softmax', use_label_encoder=False,\n",
    "            eval_metric='mlogloss', random_state=42, num_class=len(np.unique(y)),\n",
    "            tree_method='gpu_hist', gpu_id=0\n",
    "        ),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "\n",
    "    if len(y) >= 300:\n",
    "        logging.info(\"Sử dụng 10-fold Stratified cross-validation vì số lượng mẫu >= 300.\")\n",
    "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        logging.info(\"Sử dụng leave-one-out cross-validation vì số lượng mẫu < 300.\")\n",
    "        cv = LeaveOneOut()\n",
    "    aggregated_results = {\n",
    "        'model': [], 'accuracy': [], 'f1_score': [], 'recall': [], 'precision': [], 'training_time': []\n",
    "    }\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        logging.info(f\"Chạy lần thứ {run+1}\")\n",
    "\n",
    "        run_results = {\n",
    "            'model': [], 'accuracy': [], 'f1_score': [], 'recall': [], 'precision': [], 'training_time': []\n",
    "        }\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            fold_num = 1\n",
    "            accuracy_scores = []\n",
    "            precision_scores = []\n",
    "            recall_scores = []\n",
    "            f1_scores = []\n",
    "\n",
    "            start_train_time = time.time()\n",
    "\n",
    "            for train_index, test_index in cv.split(X, y):\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                precision = precision_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "                recall = recall_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "                f1 = f1_score(y_test, y_pred, average='weighted', zero_division=1)\n",
    "                accuracy_scores.append(accuracy)\n",
    "                precision_scores.append(precision)\n",
    "                recall_scores.append(recall)\n",
    "                f1_scores.append(f1)\n",
    "\n",
    "                fold_num += 1\n",
    "\n",
    "            end_train_time = time.time()\n",
    "            training_time = end_train_time - start_train_time\n",
    "            run_results['model'].append(model_name)\n",
    "            run_results['accuracy'].append(np.mean(accuracy_scores))\n",
    "            run_results['f1_score'].append(np.mean(f1_scores))\n",
    "            run_results['recall'].append(np.mean(recall_scores))\n",
    "            run_results['precision'].append(np.mean(precision_scores))\n",
    "            run_results['training_time'].append(training_time)\n",
    "        for key in aggregated_results:\n",
    "            if key != 'model':\n",
    "                aggregated_results[key].extend(run_results[key])\n",
    "            else:\n",
    "                aggregated_results[key] = run_results[key]\n",
    "    for key in aggregated_results:\n",
    "        if key != 'model':\n",
    "            aggregated_results[key] = np.mean(aggregated_results[key])\n",
    "    for i, model_name in enumerate(aggregated_results['model']):\n",
    "        summary_log_message = (f\"{model_name} - Average Accuracy: {aggregated_results['accuracy'][i]*100:.2f}%, \"\n",
    "                               f\"Average F1 Score: {aggregated_results['f1_score'][i]*100:.2f}%, \"\n",
    "                               f\"Average Recall: {aggregated_results['recall'][i]*100:.2f}%, \"\n",
    "                               f\"Average Precision: {aggregated_results['precision'][i]*100:.2f}%, \"\n",
    "                               f\"Average Training Time: {aggregated_results['training_time'][i]:.2f} seconds\")\n",
    "        print(summary_log_message)\n",
    "        logging.info(summary_log_message)\n",
    "\n",
    "    return pd.DataFrame(aggregated_results)\n",
    "\n",
    "datasets_and_n_SF = [\n",
    "   (29354, 35), (30784, 42), (31312, 195), (31552, 44),\n",
    "   (32537, 171), (33315, 2321), (37364, 140),\n",
    "   (39582, 441), (39716, 118), (44077, 23), (21122, 78)\n",
    "\n",
    "for dataset, n_SF in datasets_and_n_SF:\n",
    "    logging.info(f\"Bắt đầu xử lý dataset: {dataset} với {n_SF} đặc trưng cần chọn.\")\n",
    "    file_path = f'Gene Data/{dataset}/data.trn.gz'\n",
    "    selected_features_file = os.path.join('1.Thuc Nghiem', '1.Selected Features', 'Results', '08.10_ML', str(dataset), f'{n_SF}_dt_selected_feature_names.csv')\n",
    "    output_directory = os.path.join('1.Thuc Nghiem', '1.Selected Features', 'Results', '08.10_ML', str(dataset))\n",
    "    log_file = os.path.join(output_directory, 'experiment_log_with_selected_features.log')\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "    logging.info(f\"Bắt đầu quá trình huấn luyện và đánh giá với các đặc trưng đã chọn cho dataset {dataset}.\")\n",
    "\n",
    "    df = load_data(file_path)\n",
    "    if df is not None:\n",
    "        X = df.iloc[:, :-1]\n",
    "        y = df.iloc[:, -1]\n",
    "        selected_features = load_selected_features(selected_features_file)\n",
    "        X_selected = X[selected_features]\n",
    "        X_scaled = scale_data(X_selected)\n",
    "        results_df = train_and_evaluate_models_cv(X_scaled, y, n_runs=10)\n",
    "        save_results_to_csv(results_df, output_directory, f'results_{dataset}_nSF_{n_SF}.csv')\n",
    "    else:\n",
    "        logging.error(f\"Không thể tải dữ liệu cho dataset {dataset}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61622,
     "status": "ok",
     "timestamp": 1728003546980,
     "user": {
      "displayName": "Bích Chung Phan",
      "userId": "11159552675372297324"
     },
     "user_tz": -420
    },
    "id": "txd91rVeTqCU",
    "outputId": "a3c12d42-2a45-415c-d190-d26c9c5fcafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "## grid_search để tìm Best parameters: {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "output_directory = os.path.join('Thuc Nghiem', 'Selected Features', 'Results', '04.10', '31552')\n",
    "log_file = os.path.join(output_directory, 'experiment_log.log')\n",
    "csv_file = os.path.join(output_directory, 'grid_search_results.csv')  # Đường dẫn file CSV để ghi kết quả\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logging.info('Bắt đầu thực hiện quá trình chọn lọc đặc trưng với Boruta.')\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None, sep='\\s+')\n",
    "        logging.info(f\"Đọc dữ liệu từ file: {file_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Không tìm thấy file: {file_path}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def scale_data(X):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    logging.info(\"Dữ liệu đã được chuẩn hóa.\")\n",
    "    return X_scaled\n",
    "\n",
    "df = load_data(file_path)\n",
    "if df is not None:\n",
    "\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df.iloc[:,-1]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train_scaled = scale_data(X_train)\n",
    "    X_test_scaled = scale_data(X_test)\n",
    "    svc = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "    param_grid = {\n",
    "        'C': [1000, 10000, 100000, 1000000],\n",
    "        'gamma': [0.01, 0.05, 0.005, 0.001, 0.0001],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "    grid_search = GridSearchCV(svc, param_grid, cv=5, return_train_score=True)\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    logging.info(f\"Tham số tốt nhất: {grid_search.best_params_}\")\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n",
    "    results_df = pd.DataFrame(grid_search.cv_results_)\n",
    "    results_df.to_csv(csv_file, index=False)\n",
    "    logging.info(f\"Kết quả GridSearchCV đã được ghi vào file: {csv_file}\")\n",
    "\n",
    "else:\n",
    "    print(\"Không thể đọc dữ liệu.\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1luHCzAtuJ_prb-yaWSE3f4f0XARO3-ol",
     "timestamp": 1727919294762
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
